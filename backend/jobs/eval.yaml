# HF Jobs: Batch Evaluation
# Run full eval suite on test set after retraining

name: redline-eval
description: Evaluate fine-tuned model on test set with all scorers

compute:
  accelerator: gpu
  gpu_type: nvidia-l4
  gpu_count: 1
  max_duration_seconds: 3600

image: pytorch/pytorch:2.1.0-cuda12.1-cudnn8-runtime

env:
  HF_TOKEN: "${HF_TOKEN}"
  WANDB_API_KEY: "${WANDB_API_KEY}"
  WANDB_PROJECT: "redline-compliance"
  MISTRAL_API_KEY: "${MISTRAL_API_KEY}"
  MODEL_ENDPOINT: "${MODEL_ENDPOINT:-}"
  MODEL_ID: "${MODEL_ID:-mistral-small-latest}"
  BASELINE_RUN_ID: "${BASELINE_RUN_ID:-}"
  DATASET_REPO: "${DATASET_REPO:-mistral-hackaton-2026/redline-compliance-extraction}"
  CODE_REPO_URL: "${CODE_REPO_URL:-https://huggingface.co/mistral-hackaton-2026/redline-extractor}"

setup: |
  pip install mistralai wandb weave jsonschema requests huggingface-hub pyyaml git-lfs

  # Clone backend code
  git clone "${CODE_REPO_URL}" /workspace/repo || true
  if [ -d "/workspace/repo/backend" ]; then
    cp -r /workspace/repo/backend /workspace/backend
  fi

  # Download test data
  python -c "
from huggingface_hub import hf_hub_download
import os
repo = os.environ['DATASET_REPO']
hf_hub_download(repo_id=repo, filename='test.jsonl', repo_type='dataset', local_dir='/workspace/backend/data')
"

command: |
  cd /workspace/backend

  if [ -n "${MODEL_ENDPOINT}" ]; then
    python -m eval.finetuned_eval \
      --test-data data/test.jsonl \
      --endpoint "${MODEL_ENDPOINT}" \
      --baseline-run-id "${BASELINE_RUN_ID}"
  else
    python -m eval.finetuned_eval \
      --test-data data/test.jsonl \
      --model "${MODEL_ID}" \
      --baseline-run-id "${BASELINE_RUN_ID}"
  fi
